---
id: everybody-has-an-opinion-on-ai
title: everybody-has-an-opinion-on-ai
displayTitle: Everybody has an opinion on AI
subtitle: A hundred strangers in a comment section, and why the takes are louder than the tech
category: threads
date: 2026-02-09
thumbnail: https://images.unsplash.com/photo-1507608616759-54f48f0af0ee?q=80&w=800&auto=format&fit=crop
thumbnailAspect: banner
description: The real AI bubble isn't in the stocks. It's in the takes.
tags: [ai, bubble, speculation, hype, economy]
featured: true
related: [transformers-and-the-data-wall, alignment-is-not-a-vibe-check]
---

I didn't set out to learn anything from a Medium comment section. Nobody does. You scroll past them the way you scroll past cookie consent banners — reflexively, protectively, with the vague understanding that engaging would make your life worse.

But someone sent me a link to a post about the AI bubble, and I made the mistake of reading the comments. All of them. A hundred-something comments from strangers with credentials ranging from "Digital Anthropologist" to "SEO Expert" to "PhD" to no bio at all, and takes that ranged from brilliant to unhinged to both at the same time. And somewhere between a guy calling AI "one Ponzi scheme after another" and a startup CEO claiming his devs are "literally 10x more productive," I realized something.

--The actual bubble isn't in AI stocks. It's in AI opinions.-- We have created a secondary market of hot takes that trades at higher volume and with less underlying value than anything on the NASDAQ. Everyone has a position. Nobody has done the reading.

So I'm going to do something mildly irresponsible: I'm going to use a comment section as primary source material. Not because commenters are authorities — but because they're honest in a way that analysts, CEOs, and LinkedIn thought leaders structurally cannot be.

# The oldest trick in the air

A commenter who described himself as a "digital anthropologist" opened with a story I couldn't fully verify but also couldn't stop thinking about. He claimed that in the 1780s, after the first hot air balloon flights, an early aeronaut declared that balloons would take people to the moon in a short time. He raised huge sums on that claim. The commenter's punchline: "yes, it was a lot of hot air."

The history I *can* verify is almost as absurd. The phenomenon was called **Balloonomania**. After the Montgolfier brothers launched the first public balloon in June 1783, a wave of speculative hysteria swept across Europe. Crowds of --400,000 people-- gathered to watch ascents in Paris. Balloon-themed fashion, furniture, and merchandise flooded the market. The Montgolfiers believed they'd discovered a new gas — they called it "Montgolfier gas" — that was making their balloons rise. They hadn't. It was just hot air. Literally just heated atmosphere. They didn't even understand the basic physics of the thing they'd invented, and investors were already throwing money at them.

{bkqt/note|The template}
The tech was real. Hot air balloons genuinely flew. The investment was real — enormous sums changed hands. What wasn't real was the timeline, the scale of the promises, and the assumption that *because it works at all, it will work at any scale you want to fund*. This is the template. It has not changed in 240 years.
{/bkqt}

Railways in the 1840s — real technology, speculative mania, brutal crash, then a century of world-changing transportation. Radio in the 1920s — real technology, stock market frenzy, crash, then mass media. Dot-com in 1999 — real technology, insane valuations, spectacular implosion, then cloud computing, SaaS, and the entire digital economy that runs the world today.

The template is ancient. What's changed is the speed at which we run through it, and the dollar amounts involved. The Montgolfiers' bubble was measured in thousands of livres. The railway mania of the 1840s peaked at roughly £500 million — a third of Britain's GDP. The dot-com crash wiped out $5 trillion. And the AI bubble? In 2025, --AI-related startups captured 50% of all global venture capital--. {{Two hundred billion dollars|according to [[https://news.crunchbase.com/ai/big-funding-trends-charts-eoy-2025/|Crunchbase's 2025 year-end report]]. Foundation models alone absorbed $80 billion, up from $31 billion the year before. That's a 158% increase in one year.}} poured into a single sector. Half of all the investment money on earth, betting on one thing.

The Montgolfiers at least had an excuse. They didn't know it was just hot air.

# Everyone is right and nobody is listening

Reading that comment section was like watching a debate where every participant is correct about their specific claim and catastrophically wrong about the whole picture. They split into three camps, and each camp had the exact same problem: they could see their corner perfectly and assumed it was the entire building.

## Camp one: it's a scam

The most upvoted replies were variations on a theme. One commenter with over a thousand likes compared AI to "one Ponzi scheme after another." A PhD flatly called it "a gimmick if not a scam." Someone else predicted the burst would "deal unbelievable damage to every weird tech bro and toxic finance guy you know." A third said the quiet part out loud: --"investors realized that they could get far more return from hype than from any kind of legitimate business."--

These people are looking at the stock market and they're not wrong about what they see. Companies with no revenue getting billion-dollar valuations. A quantum computing startup with 50-something employees raising $600 million, somehow doubling its valuation to $10 billion — on the strength of technology that is, to put it diplomatically, not yet commercially useful. From a pure financial lens, parts of this market are detached from reality in ways that should make any sane person nervous.

But calling *AI itself* a scam because the stock market is overvalued is like calling electricity a scam because Enron existed.

## Camp two: you don't understand the tech

The counter-camp was equally forceful. A startup CEO reported his developers going from 300 to 2,500 lines of code per day. A software engineer wrote that AI "makes possible what used to be impossible." Another commenter snapped that "AI is helping me make a lot more money than before, so I'm not sure where the cynicism is coming from." Someone else said they'd pay $2,000 a month if they had to.

These people are looking at their own experience and they're not wrong either. The tools work. I know because I use them. Every day. For this exact kind of work, in fact.

But "it works for me" is not a macroeconomic argument. Plenty of things work for individual users while being economically unsustainable at the industry level. The product and the business model are different things, and the people in this camp consistently refuse to engage with the difference.

## Camp three: bubble, schmubble

The third group — smaller, quieter, and in my experience, closest to right — shrugged and said: of course it's a bubble. So what?

{bkqt/quote}
I have no doubt the AI bubble will burst — probably soon. But it's the same scenario as when the PC and the internet stepped into the limelight. Bubble, pop, assimilation, productivity.
{/bkqt}

The dot-com bubble burst in 2000 and killed Pets.com, Webvan, and a thousand startups whose entire business plan was "the internet, but for dogs." It did not kill the internet. Amazon survived. Google survived. eBay survived. The crash was a verdict on the *business models*, not on the technology.

This take doesn't generate engagement. It doesn't make you sound smart at dinner parties. It doesn't have the emotional punch of "it's all a scam" or the tribal energy of "you just don't get it." But it has the unfortunate quality of being historically accurate every single time.

# My portfolio says one thing, my inbox says another

Here's my situation, and I suspect it's the situation of a lot of engineers right now.

My positions in tech companies with heavy AI exposure are up over 150%. My daily toolkit includes AI-assisted coding, research, and writing. My productivity, by any honest measure, is meaningfully higher than it was two years ago. When I write code, I write it faster. When I research a topic, I reach the core faster. When I debug something, I find the bug faster. The tools are --genuinely, measurably useful--. I wrote about [[threads/transformers-and-the-data-wall|why the underlying architecture works]] — the technology is not hype. It is real math doing real things.

My LinkedIn inbox, meanwhile, has gone quiet. Not because I'm less qualified — because the market is contracting. Entry-level tech postings in the US have dropped by an estimated --67%--. In the UK, tech graduate roles fell 46% in 2024 with projections for {{another 53% drop|[[https://www.rezi.ai/posts/entry-level-jobs-and-ai-2026-report|Rezi.ai's 2026 entry-level report]] documents the collapse across the US, UK, EU, and India. EU countries saw a 35% decline in junior tech positions in 2024 alone.}} by 2026. Senior roles are flat. The overall tech job market is in what analysts politely call a "low-hire, low-fire equilibrium," which is corporate-speak for "nobody's getting fired and nobody's getting hired, and if you're a fresh graduate, best of luck."

{bkqt/keyconcept|The duality}
I am literally more productive than I've ever been, using tools that are eliminating the entry-level positions that people like me once held to *become* productive in the first place. My stocks go up because AI makes senior engineers more efficient. The junior hiring pipeline dries up for the exact same reason. These are not contradictory facts. They are the same fact, viewed from different floors of the building.
{/bkqt}

And this is the part that neither the "it's a scam" camp nor the "you don't get it" camp wants to sit with. The technology works. The economics are brutal. The human cost is real and unevenly distributed. All three things are true simultaneously, and collapsing any of them into a slogan — "AI is overhyped" or "AI is transformative" — is the kind of intellectual shortcut that makes me tired.

I'm tired.

I'm tired of reading LinkedIn posts from people who have never trained a model explaining that AI will replace all software engineers by Thursday. I'm tired of reading LinkedIn posts from people who have never shipped production code explaining that AI *can't* write production code. I'm tired of YouTube thumbnails with red arrows pointing at ChatGPT logos. I'm tired of the word "disruption." And I'm tired of comment sections — yes, including the one I'm using as primary source material for this article, the irony is not lost on me, thank you.

One commenter cut through all of it: "until the AI bubble bursts, so many people will lose their jobs and so many creative minds will lose their hope. In the end, it doesn't even matter if it bursts or not. The damage is already done."

That's the one that sat with me.

# The bubble in understanding

The number that matters: in 2025, AI captured --half of all venture capital deployed worldwide--. $202 billion. Up 75% from the year before. Foundation models alone — the raw engines, the stuff companies like OpenAI and Anthropic build — absorbed $80 billion, more than doubling from $31 billion in 2024.

When I say "bubble," I'm not making a philosophical judgment about whether AI is useful. I'm making a mathematical observation about what happens when half the money on earth bets on one thing.

And the problem isn't the technology. The technology is real. I use it. It works. A commenter who builds AI data centers confirmed that the hardware advances are genuine. Another pointed out that banks are already using machine learning for investment decisions in sub-second timeframes. One developer said the tools turned non-coders into coders and coders into code reviewers. Fair enough — all real.

The problem is that --the people writing the checks don't understand what they're buying--.

A CEO who can't explain what a {{transformer|the neural network architecture behind every major AI system — GPT, Claude, Gemini, LLaMA. It processes text by computing attention scores between all words simultaneously, rather than reading them sequentially. The math fits on one line. The emergent behavior doesn't fit in anyone's head.}} allocates 30% of the IT budget to "AI transformation." A venture capitalist who has never seen a loss function funds a startup because the pitch deck says "AI-native." A pension fund manager who doesn't know the difference between training and inference puts retirees' money into NVIDIA stock because it went up last quarter.

These are not people making informed bets on technology. These are people making emotional bets on *narrative*. And narratives correct. Always.

{bkqt/warning|What the correction looks like}
When the narrative corrects — and it will — the people who lose money will not be the engineers building useful AI tools in quiet companies with actual revenue. The people who lose money will be the investors who put billions into companies whose entire value proposition was "AI" as a prefix. The ones who funded the balloon ride to the moon. The tech will survive. The hype layer won't. And the gap between the two is where the pain lives.
{/bkqt}

A commenter who works in finance nailed the mechanism: the existence of vast and growing levels of national debt means more and more public money is being constantly funneled to the finance sector — "which is where speculation lives. They will put that money into something." The money doesn't care what the something is. AI, crypto, quantum, fusion, whatever sounds expensive enough to be plausible. The money just needs a vehicle. AI is this decade's vehicle.

**[Infographic suggestion: The Venn Diagram of AI Opinions]** *Three circles. Circle 1: "People who invest in AI" — large. Circle 2: "People who have strong opinions about AI" — even larger, almost fully overlapping Circle 1. Circle 3: "People who can explain what a transformer does" — a tiny circle barely touching the other two. The triple overlap is a single pixel.*

But it gets worse. There's a bubble *inside* the bubble that almost nobody's watching.

Below the headline AI companies — the OpenAIs, the Anthropics, the model builders — there's an entire ecosystem of infrastructure startups: GPU cloud providers, vector database companies, MLOps platforms, AI deployment tools. The "picks and shovels" of the gold rush. And here's what the picks-and-shovels crowd doesn't want to hear: --most of them are solving problems that the major cloud platforms will absorb in 18 months--.

{bkqt/note|The shovel problem}
This isn't speculation — it's already happening. **Weights & Biases**, once the flagship MLOps platform, got {{acquired by CoreWeave|the GPU cloud provider bought them outright. Not a partnership. An acquisition. The independent MLOps play collapsed into an infrastructure play, which itself is a bet on continued GPU demand.}} in 2025. The standalone vector database market — **Pinecone**, **Weaviate**, **Milvus** — watched their value proposition evaporate as PostgreSQL added native vector support and the database giants made their move. Snowflake acquired Crunchy Data for $250 million. Databricks spent $1 billion on Neon. The purpose-built vector DB became a *feature* of the general-purpose database, not a product. 2025 was a record year for data infrastructure M&A. The consolidation is eating the "picks and shovels" layer alive, and most of the companies being digested haven't updated their pitch decks yet.
{/bkqt}

A commenter in a different thread put it bluntly: --"95% of these companies are already dead. They just don't know it yet."-- The infrastructure bubble is arguably more fragile than the model bubble, because at least the models do something novel. The infrastructure companies are building things that bigger companies can replicate with a team and a quarter.

# What actually happens after

Everyone in that comment section cited the dot-com bubble. Not one of them followed the analogy all the way through.

Here's what actually happened. The NASDAQ lost 78% of its value between March 2000 and October 2002. Trillions evaporated. Companies with *real revenue* — Amazon, eBay, Priceline — lost 80-95% of their stock price anyway, because when panic hits, it doesn't check your balance sheet. Amazon went from $107 to $7. Seven dollars. A company that was already profitable, with millions of customers, trading at the price of a sandwich.

And then — quietly, without a single "thought leader" noticing — the actual revolution happened.

Cloud computing. SaaS. Social media. E-commerce at scale. The smartphone era. The entire digital economy that currently runs civilization was built --after-- the bubble, not during it. The bubble was the awkward, overfunded, over-hyped first date. The revolution was the two decades of compound utility that followed.

{bkqt/keyconcept|After the crash}
The dot-com crash didn't prove that the internet was fake. It proved that --most early internet business models were fake--. The technology survived because it was genuinely useful. The speculation died because it was genuinely speculative. These are different things. Confusing them is the central error of the "AI is a bubble" crowd — and, paradoxically, also the central error of the "AI is not a bubble" crowd. The bubble is real AND the tech is real. Both. Simultaneously. The inability to hold both ideas in your head at the same time is the actual bubble.
{/bkqt}

If the pattern holds — and it has held for 240 years, through balloons and railways and radio and the internet — what comes after the AI correction will be more consequential than anything happening now. The useful tools will survive. The grift layer will evaporate. The CEOs who allocated budget to "AI transformation" without understanding what they bought will quietly un-allocate it. And the engineers who built things that actually work will keep building, same as they were before anyone on LinkedIn had an opinion.

A commenter wrote something I keep coming back to: "those who survive will be far more valuable and impactful than any company in history." That's either naive optimism or the most accurate prediction in the thread. I genuinely don't know which.

And there's a wildcard that nobody at the investment conferences wants to discuss: --open source--. Optimized models running on consumer hardware — no data center required, no API bill, no vendor lock-in. A commenter predicted that "open source optimized models for consumer hardware will kill big companies in 4-5 years." Maybe. Maybe not. But the fact that a viable open-source path exists means that the entire centralized infrastructure play — the hundred-billion-dollar bet on GPU clouds and proprietary APIs — has a timer on it. The picks and shovels become irrelevant when people start finding gold in their backyard.

**[Infographic suggestion: The Hype Pipeline]** *A horizontal timeline: Hot air balloons (1783) → Railway mania (1840s) → Radio stocks (1920s) → Dot-com (1999) → Crypto (2021) → AI (2024-25) → Quantum (2027?). Under each entry, the same three-line checklist repeats: "Real technology. Wild promises. Money from people who don't understand it." The pipe gets wider and shinier with each iteration, but the pattern is identical. At the far right, a faded label: "Next: ???"*

# The escape hatch

Speaking of the next thing — several commenters noticed that the hype machine is already warming up a replacement. **Quantum computing.** The theory being: once the AI bubble pops, investors will need somewhere to park their optimism, and quantum computing is exotic enough to absorb it.

One commenter's prediction deserves a plaque: --"my guess is quantum computing investment will pick up as soon as they convince us they will deliver flying or self-driving vehicles."--

A researcher who actually works with the technology pointed out something more substantive: quantum computers are good at specific algorithmic problems that involve very little data. Loading data into a quantum system is slow. The qubit counts are tiny. And the idea that quantum computing will "solve AI's scaling problem" is roughly as coherent as the idea that buying a faster blender will fix your diet. The tools do different things. But coherence has never been a requirement for investment theses.

{bkqt/quote}
Every time someone says there's a limit, they are proved invariably wrong because they always confuse the current trajectory with a physical law.
{/bkqt}

Maybe. Or maybe some limits *are* physical laws, and the people who point them out aren't pessimists — they're physicists. The history of technology is full of both: limits that turned out to be temporary engineering problems, and limits that turned out to be thermodynamics. The trouble is that investors can't tell the difference. And they don't need to — because by the time the answer is clear, they've already moved their money to the next balloon.

---

I went into that comment section expecting noise. What I found was a decent cross-section of every argument about AI that exists right now — compressed, stripped of corporate polish, and delivered with the raw energy of people who have nothing to sell.

The "it's a bubble" people are right about the money. The "it works" people are right about the technology. The "it'll be fine" people are right about the pattern. None of them are talking to each other.

--The bubble will pop.-- Some companies will die. Some investors will lose badly. The financial correction will be painful and someone on LinkedIn will call it "unexpected." The junior engineers who got squeezed out during the frenzy will be the collateral damage that nobody discusses at the conferences. And somewhere, a creative mind who lost hope during the gold rush will read a headline about the crash and feel nothing, because the damage was already done before the price corrected.

And then — because this is how it always goes — the people who actually understand the technology will keep building. The useful tools will keep working. The hype layer will burn off like morning fog, and underneath it will be something genuinely transformative, built by people who were too busy shipping to have opinions about whether it was a bubble.

My stocks might be down 40% by then. My tools will still work. And the next comment section will be arguing about quantum.
