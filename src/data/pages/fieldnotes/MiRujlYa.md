---
uid: "MiRujlYa"
address: "ML//benchmark//MATH"
name: "MATH"
date: "2026-02-26"
---
- Competition-level math problems from AMC and AIME contests
- Frontier variants: MATH level 5 (hardest subset), FrontierMath (unsolved research-level problems)
- The benchmark that proved [[ct4swTMy|chain of thought]] and [[Kp4jIz9L|reasoning models]] actually help â€” dramatic accuracy jumps
