---
uid: "S1sknKcL"
address: "ML//Multimodal//BLIP"
name: "BLIP"
date: "2026-02-26"
---
- Bootstrapping Language-Image Pre-training (Salesforce). BLIP (2022) and BLIP-2 (2023)
- BLIP-2 innovation: Q-Former — a lightweight querying [[QtZjVPKo|transformer]] bridging a frozen vision encoder to a frozen LLM
- No need to fine-tune the vision or language model — only the Q-Former trains. Extremely parameter-efficient
- Superseded [[pJmh7BBn|CLIP]] for many tasks. SigLIP (Google) and PaliGemma are related successors
---
[[pJmh7BBn|CLIP]] :: BLIP/BLIP-2 superseded CLIP — CLIP does contrastive matching (image↔text), BLIP adds generative capabilities (caption, answer, reason)
