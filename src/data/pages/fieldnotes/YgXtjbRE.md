---
uid: "YgXtjbRE"
address: "ML//benchmark//SWE-Bench"
name: "SWE-Bench"
date: "2026-02-26"
---
- Real GitHub issues from popular Python repos — model must write a patch that passes the test suite
- Tests [[WA8fVNaT|agent]] capabilities: planning, code understanding, debugging — not just generation
- SWE-Bench Verified: human-validated subset. Adopted by Anthropic, Devin, OpenAI as the de-facto agent benchmark
---
[[WA8fVNaT|agent]] :: SWE-Bench became the primary agent benchmark — solving real issues requires planning, exploration, and multi-step tool use
