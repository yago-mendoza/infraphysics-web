---
uid: "z9wBHP2x"
address: "NVIDIA//A100"
name: "A100"
date: "2021-06-12"
---
- The GPU that trained GPT-3, PaLM, and most 2021-2023 LLMs
- 80GB HBM2e, Tensor Cores for mixed-precision training
- Clusters of thousands defined the scaling era. ~$10K-$15K per card.
---
[[j7ZpMrPl|H100]] :: the next generation — 2-3× training throughput plus dedicated Transformer Engine
