---
uid: "uuSdeqbX"
address: "ML//neural network//activation function//GELU"
name: "GELU"
date: "2020-03-15"
---
- Gaussian Error Linear Unit — smooth approximation to [[ZS34nG4d|ReLU]]
- x * Φ(x) where Φ is the Gaussian CDF
- Used in [[QtZjVPKo|Transformers]], BERT, GPT — slightly better than ReLU for language tasks
