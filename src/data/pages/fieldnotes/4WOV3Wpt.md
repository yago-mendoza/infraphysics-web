---
uid: "4WOV3Wpt"
address: "ML//Transformer//encoder-decoder"
name: "encoder-decoder"
date: "2018-08-20"
---
- The original Transformer architecture: encoder processes input bidirectionally, decoder generates output autoregressively
- T5 kept this structure. GPT dropped the encoder (decoder-only). [[MwbJnjdN|BERT]] dropped the decoder (encoder-only).
- The architectural split that defined the field: generation vs understanding
