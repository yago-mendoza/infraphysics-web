---
address: "GPU//architecture"
date: "2026-02-05"
---
The internal design of a [[GPU]] â€” thousands of streaming multiprocessors (NVIDIA) or compute units (AMD) grouped into warps/wavefronts that execute in lockstep. Memory hierarchy includes registers, shared memory, L1/L2 caches, and high-bandwidth GDDR or HBM. Architecture choices determine throughput for graphics, [[ML]] training, and scientific workloads. [[GPU//discrete]] cards push bleeding-edge architectures; [[GPU//integrated]] units share die area with the [[CPU]].
[[GPU]]
[[GPU//discrete]]
[[GPU//integrated]]
[[ML]]
