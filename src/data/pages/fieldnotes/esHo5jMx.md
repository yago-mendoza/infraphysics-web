---
uid: "esHo5jMx"
address: "ML//Training//fine-tuning"
name: "fine-tuning"
date: "2021-06-12"
---
- Take a [[2oNdlB5L|pre-trained]] model, train further on task-specific data
- Full fine-tuning updates all weights â€” expensive, risks catastrophic forgetting
- [[3kgsj4Y4|LoRA]] and adapters make it cheaper: freeze most weights, train a small delta
- The bridge between general knowledge and specific skill
