---
uid: "e9JZ4ItW"
address: "ML//Training//fine-tuning//QLoRA"
name: "QLoRA"
date: "2026-02-26"
---
- Quantized [[3kgsj4Y4|LoRA]]: load the base model in 4-bit [[qY2jOLny|precision]], train LoRA adapters in 16-bit
- Fine-tune a 65B model on a single 48GB GPU â€” brought model customization to consumer hardware
- FSDP+QLoRA: scale across multiple GPUs for even larger models
- The democratization inflection point: anyone with a decent GPU can customize frontier-class models
