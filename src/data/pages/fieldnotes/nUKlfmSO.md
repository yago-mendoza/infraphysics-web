---
uid: "nUKlfmSO"
address: "ML//DeepSeek"
name: "DeepSeek"
date: "2026-02-26"
---
- Chinese AI lab. V1 through V3 pushed open-weight models to frontier performance at a fraction of the cost
- V3: [[x5qaZizz|Mixture of Experts]] architecture — 671B total params, ~37B active per token
- R1 (Jan 2025): matched o1-level reasoning using [[NYb6zLJ5|reinforcement learning]] with [[HRgl17gQ|GRPO]] — no supervised fine-tuning for the reasoning phase
- Published full training recipes, open-sourced weights. Forced pricing collapse across the industry
---
[[hupst9j9|open source model]] :: pushed the frontier of what open-weight models can achieve — V3 and R1 compete with GPT-4 class models at open weights
