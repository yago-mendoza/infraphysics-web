---
uid: "sRfwFcjG"
address: "ML//GPT//InstructGPT"
name: "InstructGPT"
date: "2026-02-26"
---
- OpenAI (2022). [[gfRFzkBN|GPT-3]] aligned to follow instructions via [[0f5GJDwc|RLHF]]
- The 3-step recipe: [[qcqxPFA0|SFT]] on demonstrations → train a [[83orykQl|reward model]] on human comparisons → optimize with [[rxVjxTLA|PPO]]
- Bridge from GPT-3 to [[Wb0yDrNZ|ChatGPT]] — proved alignment makes models both safer and more useful
- 1.3B InstructGPT preferred over 175B GPT-3 by human raters. Alignment beats scale for user satisfaction
---
[[0f5GJDwc|RLHF]] :: InstructGPT introduced the 3-step RLHF pipeline to production — the exact recipe (SFT → reward model → PPO) that became the industry standard
