---
address: "ML//TPU"
date: "2026-02-05"
---
Tensor processing unit â€” Google's custom [[ASIC]] designed for [[ML]] training and inference at datacenter scale. Uses a systolic array architecture to stream matrix operations with minimal memory access. TPU v4 pods interconnect thousands of chips via custom high-bandwidth networks. Exposed as cloud instances (Google Cloud TPU). Represents the extreme end of ML hardware specialization.
[[ASIC]]
[[ML]]
