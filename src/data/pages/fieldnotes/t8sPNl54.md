---
uid: "t8sPNl54"
address: "ML//TPU"
name: "TPU"
date: "2026-02-05"
---
- Google's custom [[6YzJQiig|ASIC]] designed for [[7aLJOACt|ML]] training and inference at datacenter scale
- Uses a systolic array architecture to stream matrix operations with minimal memory access
- TPU v4 pods interconnect thousands of chips via custom high-bandwidth networks
- Exposed as cloud instances (Google Cloud TPU)
- Represents the extreme end of ML hardware specialization
- Math embedded as silicon; both TPU and [[1yDGHLLU|NPU]] are [[6YzJQiig|ASIC]]s optimized for tensor multiplication
