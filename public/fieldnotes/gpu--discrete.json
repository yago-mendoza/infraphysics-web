{"content":"<p>A standalone <a class=\"wiki-ref\" data-address=\"GPU\">GPU</a> on its own PCB with dedicated GDDR/HBM memory, connected to the host <a class=\"wiki-ref\" data-address=\"CPU\">CPU</a> via PCIe or NVLink. Delivers maximum compute throughput for <a class=\"wiki-ref\" data-address=\"ML\">ML</a> training, rendering, and HPC. Power draw ranges from 75W (entry) to 700W+ (datacenter). Data must be explicitly transferred between host <a class=\"wiki-ref\" data-address=\"RAM\">RAM</a> and device memory, adding latency but offering massive bandwidth on-card.\n<a class=\"wiki-ref\" data-address=\"GPU\">GPU</a>\n<a class=\"wiki-ref\" data-address=\"CPU\">CPU</a>\n<a class=\"wiki-ref\" data-address=\"RAM\">RAM</a>\n<a class=\"wiki-ref\" data-address=\"ML\">ML</a></p>\n"}