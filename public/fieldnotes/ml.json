{"content":"<p>Machine learning â€” algorithms that improve through data rather than explicit programming. Training runs on <a class=\"wiki-ref\" data-address=\"GPU\">GPU</a> clusters or <a class=\"wiki-ref\" data-address=\"ML//TPU\">TPU</a> accelerators; inference can happen on cloud GPUs, edge <a class=\"wiki-ref\" data-address=\"ML//NPU\">NPU</a> cores, or even <a class=\"wiki-ref\" data-address=\"chip//MCU\">MCU</a> devices via <a class=\"wiki-ref\" data-address=\"ML//TinyML\">TinyML</a>. The boundary between software and hardware blurs as ML models get baked into silicon.\n<a class=\"wiki-ref\" data-address=\"ML//TinyML\">TinyML</a>\n<a class=\"wiki-ref\" data-address=\"ML//NPU\">NPU</a>\n<a class=\"wiki-ref\" data-address=\"ML//TPU\">TPU</a></p>\n"}